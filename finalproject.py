# -*- coding: utf-8 -*-
"""finalproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wosG_N4Qnngcmlh5WZq4V-I72a3RM6NA
"""

!pip install datasets tensorflow scikit-learn

from datasets import load_dataset

# Load customer support tickets dataset
dataset = load_dataset("Tobi-Bueck/customer-support-tickets")
print(dataset)

import pandas as pd

# Convert Hugging Face dataset to pandas DataFrame
df = pd.DataFrame(dataset['train'])
print(df[['body', 'queue']].head())

import numpy as np
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Simple cleaning: lowercasing
texts = df['body'].astype(str).str.lower().tolist()
labels = df['queue'].tolist()

# Encode ticket queues as numbers
le = LabelEncoder()
labels_encoded = le.fit_transform(labels)

# Tokenize text
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
X = pad_sequences(sequences, maxlen=100)
y = np.array(labels_encoded)

# Check results
print("Text shape:", X.shape)
print("Label shape:", y.shape)
print("Classes:", le.classes_)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

num_classes = len(le.classes_)

model = Sequential([
    Embedding(5000, 64, input_length=100),
    LSTM(64),
    Dense(num_classes, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

print(model.summary())

# Split data (keeping it simple)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Train model
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=2,
    batch_size=32
)

from sklearn.metrics import classification_report, confusion_matrix

# Predict on test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Print metrics
print("Classification Report:\n", classification_report(y_test, y_pred_classes, target_names=le.classes_))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_classes))

import requests

# Use one sample from test set
sample_idx = 0
sample_text = df.iloc[sample_idx]['body']

endpoint = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
api_key = "AIzaSyAHTCEybRSEWmZKVL0ALBaCMnN_VyHnnKY"

prompt = f"Draft a polite customer acknowledgment for this support ticket: '{sample_text}'. Assure them their issue will be addressed soon.reply in English"

payload = {
  "contents": [
    {
      "parts": [
        {"text": prompt}
      ]
    }
  ]
}

headers = {
    "Content-Type": "application/json"
}

response = requests.post(
    f"{endpoint}?key={api_key}",
    headers=headers,
    json=payload
)
reply = response.json()['candidates'][0]['content']['parts'][0]['text']

print("Sample ticket:", sample_text)
print("Gemini reply:", reply)